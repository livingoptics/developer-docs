{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"index.html","title":"Developer documentation","text":"<p>Welcome to the Living Optics Developer documentation.</p> <p>Tip</p> <ul> <li>Some links on this site require you to register with us and be logged in to our cloud portal to get access.</li> <li>Product documentation for Subscription Tier users can be found at https://docs.livingoptics.com.</li> </ul>"},{"location":"index.html#contents","title":"Contents","text":"<ul> <li> <p> Discover</p> <p>Explore the potential of hyperspectral video information.</p> <p> Examples</p> </li> <li> <p> Develop</p> <p>Install software and explore the data samples.</p> <p> Getting started</p> </li> <li> <p> Learn</p> <p>Bring spectral information to computer vision.</p> <p> Tutorials</p> </li> <li> <p> Resources</p> <p>Explore the Living Optics developer repositories.</p> <p> Github</p> </li> </ul>"},{"location":"examples/index.html","title":"Examples","text":"<ul> <li>Python examples : Showcasing the application of spectral information to computer vision tasks.</li> <li>SDK examples : Illustrating development with the Living Optics Software Development Kit.</li> </ul>"},{"location":"getting-started/index.html","title":"Getting started","text":""},{"location":"getting-started/index.html#contents","title":"Contents","text":"<ul> <li>First steps: Register to the cloud, install software and explore some data samples.</li> <li>Data formats: Overview of data formats.</li> <li>Cloud portal: Overview of the Living Optics cloud portal.</li> </ul>"},{"location":"getting-started/cloud-orientation.html","title":"Cloud Portal","text":"<p>The Living Optics Cloud portal is the main hub for interacting with Living Optics. It is where the latest software packages, sample data, documentation and much more can be accessed, dependant on the subscription tier you are signed up to.</p> <p>As part of self-registration to the cloud you will automatically be put onto the free tier. </p>"},{"location":"getting-started/cloud-orientation.html#to-upgrade-the-subscription-tier","title":"To upgrade the subscription tier","text":"<ul> <li>Go to the <code>Subscription</code> menu in the toolbar</li> <li>Then select the <code>Active Subscription Details</code> tab.</li> <li>Then select <code>Upgrade Subscription</code>.</li> </ul> <p>This sends a request to upgrade the tier to our cloud portal administrator to review.</p>"},{"location":"getting-started/cloud-orientation.html#to-end-cloud-portal-access","title":"To end cloud portal access","text":"<ul> <li>Go to the <code>Subscription</code> menu in the toolbar</li> <li>Then select the <code>Active Subscription Details</code> tab.</li> <li>Then select <code>End Subscription</code>.</li> </ul> <p>This sends a request to end access to our cloud portal administrator to review.</p>"},{"location":"getting-started/dataformats.html","title":"Data formats","text":"<p>An introduction to Living Optics Camera data formats.</p>"},{"location":"getting-started/dataformats.html#contents","title":"Contents","text":"<ul> <li>'LOFMT' Spatial-spectral data format</li> <li>'LORAW' RAW data format</li> </ul>"},{"location":"getting-started/dataformats.html#lofmt-data","title":"'LOFMT' data","text":"<p>Files with the extension <code>.lo</code> signify spatial-spectral video recordings from the Living Optics Camera stored in a proprietary 'LOFMT' data format. The data is organised as a sequence of frames of 'Scene data' plus 'Spectral data'.</p> <p>We can view a frame of LOFMT data as a 'Scene View' image and associated 'Spectral samples' as below.</p> <p> Scene View</p> <p> Scene view overlaid with spectral sampling positions</p> <p>Note that the spectral sampling is sparse, spatially high-resolution and distributed over the scene.</p>"},{"location":"getting-started/dataformats.html#processing-lofmt-data","title":"Processing LOFMT data","text":"<p>This data format lends itself to further analysis as illustrated below.</p>"},{"location":"getting-started/dataformats.html#spectral-sampling","title":"Spectral sampling","text":"<p>A debayered colour image of the scene view is shown along with the average spectrum for three regions of interest (ROI) in the scene corresponding to three colours in the chart.</p> Scene view (Debayered) showing ROIs Average spectrum for each ROI"},{"location":"getting-started/dataformats.html#rendering-scenes-in-colour","title":"Rendering scenes in colour","text":"<p>The figure below compares simple colour renders of the Scene view and Encoded view. The pseudo-colour of the Encoded view has been created from the spectral samples at 625nm, 550nm, 475nm and performing a simple nearest neighbour upsampling to the scene view pixel resolution.</p> Scene view (Debayered) Encoded view (pseudo colour)"},{"location":"getting-started/dataformats.html#higher-resolution-spectral-sampling","title":"Higher resolution spectral sampling","text":"<p>Higher resolution spectral sampling is possible using various techniques. One simple method is to use multiple frames and motion of the camera.</p> <p>An example of the typical motion that can be used to resample the scene and increase the spatial resolution of spectral images is shown below.</p> Motion Enhanced spectral resolution <p>For more information  on the data format please refer to the SDK API Reference.</p>"},{"location":"getting-started/dataformats.html#spectral-analysis-to-classify-liquids","title":"Spectral analysis to classify liquids","text":"<p>As a final example in this section we show the classification of liquids using LOFMT spatial spectral data.</p>"},{"location":"getting-started/dataformats.html#loraw-data","title":"'LORAW' data","text":"<p>The raw unprocessed output from the Living Optics Camera may also be stored in a proprietary 'LORAW' data format. Files with extension <code>.loraw</code> are associated with this raw data format where raw video data recordings are organised as frames of 'Raw Scene data' plus 'Raw Encoded data'.</p> <p>We can view a frame of raw data as images: a 'Raw Scene View' and; a 'Raw Encoded View' as below:</p> 'Raw Scene View' 'Raw Encoded View' <p>The RAW Scene View is a Raw RGB bayer image. The RAW Encoded View is a grayscale image encoding spatial-spectral information.</p> <p>A decoding routine and 'calibration' are used to convert 'LORAW' format data into 'LOFMT' format data. This conversion is performed in real time during data capture or in the post-capture processing depending upon the application use case.</p> <p>For more information on the data format please refer to the SDK API Reference</p>"},{"location":"getting-started/software-and-data-samples.html","title":"Software install and sample data","text":"<p>This tutorial will guide you through installation of software tools on your workstation, download of sample data and some simple data analysis steps.</p>"},{"location":"getting-started/software-and-data-samples.html#software-installation","title":"Software installation","text":"<p>The tools you need are bundled with the Living Optics Camera Software Development Kit (SDK), which is available for download on our cloud portal.</p> <ul> <li>Register with the cloud portal to gain access.</li> </ul> <p>Tip</p> <p>If you have already previously registered with our cloud portal, you can just login using your credentials.</p> <ul> <li>Download and follow the SDK install guide here to get setup on your workstation.</li> </ul>"},{"location":"getting-started/software-and-data-samples.html#sample-data","title":"Sample Data","text":"<ul> <li>Grab some sample data by pointing your browser here and click the <code>Download</code> icon. Unzip to a local directory on your workstation.</li> </ul>"},{"location":"getting-started/software-and-data-samples.html#next-steps","title":"Next steps","text":"<ul> <li>Explore the sample data files with the <code>data</code> tool included as part of the Living Optics SDK by:<ul> <li>Opening a terminal.</li> <li>Activating your virtual environment (created during the SDK install process).</li> <li>Typing <code>Data</code> to start the GUI tool.</li> </ul> </li> <li>Checkout the <code>analysis</code> tool using a <code>.lo</code> dataset by following our tutorial.</li> <li>Go even deeper with specific python code examples for computer vision tasks at our github page.</li> </ul>"},{"location":"resources/index.html","title":"Resources","text":"<ul> <li>Github : Explore the Living Optics developer repositories.</li> <li>Product documentation : Product documentation for registered users.</li> <li>Hugging Face: Checkout Living Optics hyperspectral datasets on Hugging Face.</li> </ul>"},{"location":"tutorials/index.html","title":"Tutorials","text":""},{"location":"tutorials/index.html#contents","title":"Contents","text":"<ul> <li>Getting started tutorial - analysis: Get started with analysing a <code>.lo</code> data file</li> </ul>"},{"location":"tutorials/gs-analysis.html","title":"Getting started SDK tutorial","text":"<p>This tutorial covers how to do the following using the tools:</p> <ul> <li>Opening a <code>.lo</code> file</li> <li>Performing segmentation of a video using spectral information about two types of object.</li> </ul>"},{"location":"tutorials/gs-analysis.html#pre-requisites","title":"Pre-requisites","text":"<ul> <li>Have downloaded and installed the SDK</li> <li>Have activated the python virtual environment <code>source venv/bin/activate</code></li> </ul>"},{"location":"tutorials/gs-analysis.html#download-the-example-data-file","title":"Download the example data file","text":"<ul> <li>Get an example <code>.lo</code> data file from the cloud portal and download to your workstation.</li> </ul>"},{"location":"tutorials/gs-analysis.html#open-the-lo-file","title":"Open the <code>.lo</code> file","text":"<p>A <code>lo</code> file is the processed readout of data from the Living Optics Camera. It consists of spectral lists, combined with the raw (bayered) scene frame image and metadata associated with the frame.</p> <ul> <li>Run the analysis tool with the filepath to the example <code>.lo</code> file</li> </ul> <pre><code>analysis --file /path/to/file.lo\n</code></pre> <ul> <li>The tool UI will appear and the file will automatically begin playing on a loop.</li> <li>Flip the view vertically using the 'Flip Y' button, to make it easier to recognize what is being viewed.</li> <li>Press the <code>Decode Spectra</code> button below the <code>Viewer</code>.</li> <li>In the Analysis routine dropdown, select the \"SpectralSegmentation\" option.</li> </ul> <p></p>"},{"location":"tutorials/gs-analysis.html#analyze-the-scene","title":"Analyze the scene","text":"<ul> <li>Right-click in the 'Spectrum Viewer'</li> <li>Go to `Plot Options' &gt; 'Load Spectra from file...' and select the strawberry-spectrum.json file.</li> </ul> <p>This will load in previously saved spectra from this same .lo file of a strawberry and a strawberry leaf.</p> <p></p> <ul> <li>In the Analysis sidebar of the tool, type in <code>loaded-strawberry</code> into the <code>spectrum1</code> box.</li> <li>Then type in <code>loaded-leaf</code> into the <code>spectrum2</code> box.</li> <li>Finally select the <code>use_spectrum1</code> and <code>use_spectrum2</code> tick box for use.</li> </ul> <p></p> <p>You will now see that the <code>Viewer</code> is playing the preview stream, with a segmentation map overlaid onto it. The strawberry and strawberry leaves have been spectrally segmented using the hyperspectral information contained in the video. This technique can be applied to any object you wish to identify in a given scene.</p> <p>This is the end of this tutorial. You have now gone through the basics of opening a <code>.lo</code> file in one of the SDK tools, as well as the first step on using hyperspectral data in the same way an agricultural drone or satellite would.</p>"},{"location":"tutorials/gs-analysis.html#next-steps","title":"Next steps","text":"<p>Explore the SDK further with more information on what the tools can do or dive deeper with the SDK Code example basics.</p> <p>To understand more of what the <code>.lo</code> file data format is.</p>"}]}